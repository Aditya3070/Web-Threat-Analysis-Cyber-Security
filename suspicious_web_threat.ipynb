{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae90827-5524-4327-bfef-17a7ddd568f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb3327-dd3d-43ae-9c7a-4508f946a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a DataFrame\n",
    "data = pd.read_csv(\"/content/web threat analysis/CloudWatch_Traffic_Web_Attack.csv\")\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5579ae-8d30-4e2b-8814-4269b4ace6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df_unique = data.drop_duplicates()\n",
    "\n",
    "# Convert time-related columns to datetime format\n",
    "df_unique['creation_time'] = pd.to_datetime(df_unique['creation_time'])\n",
    "df_unique['end_time'] = pd.to_datetime(df_unique['end_time'])\n",
    "df_unique['time'] = pd.to_datetime(df_unique['time'])\n",
    "\n",
    "# Standardize text data\n",
    "df_unique['src_ip_country_code'] = df_unique['src_ip_country_code'].str.upper()\n",
    "\n",
    "# Display information\n",
    "df_unique.info()\n",
    "df_unique.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5141c-43d7-46c3-a2d1-6cd1f4565d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate duration of connection\n",
    "df_unique['duration_seconds'] = (df_unique['end_time'] - df_unique['creation_time']).dt.total_seconds()\n",
    "\n",
    "# StandardScaler for numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_unique[['bytes_in', 'bytes_out', 'duration_seconds']])\n",
    "\n",
    "# OneHotEncoder for categorical features\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_features = encoder.fit_transform(df_unique[['src_ip_country_code']])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=['scaled_bytes_in', 'scaled_bytes_out', 'scaled_duration_seconds'])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['src_ip_country_code']))\n",
    "\n",
    "# Concatenate data\n",
    "transformed_df = pd.concat([df_unique, scaled_df, encoded_df], axis=1)\n",
    "transformed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9543b4d-f001-40a1-a2b5-99efdba82fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "numeric_df = transformed_df.select_dtypes(include=['float64', 'int64'])\n",
    "correlation_matrix_numeric = numeric_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix_numeric, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190344e-af3e-4e6c-afe4-656c5e93e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Bar Chart for Detection Types by Country\n",
    "detection_types_by_country = pd.crosstab(transformed_df['src_ip_country_code'], transformed_df['detection_types'])\n",
    "detection_types_by_country.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "plt.title('Detection Types by Country Code')\n",
    "plt.xlabel('Country Code')\n",
    "plt.ylabel('Frequency of Detection Types')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Detection Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c664ec6-3f94-4960-9d50-399cc6314e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "transformed_df['is_suspicious'] = (transformed_df['detection_types'] == 'waf_rule').astype(int)\n",
    "\n",
    "# Features and Labels\n",
    "X = transformed_df[['bytes_in', 'bytes_out', 'scaled_duration_seconds']]\n",
    "y = transformed_df['is_suspicious']\n",
    "\n",
    "# Split into training & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict & Evaluate\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07b6fe-ea63-4f1d-b60c-d18ccd0530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build Neural Network\n",
    "model = Sequential([\n",
    "    Dense(8, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=8, verbose=1)\n",
    "\n",
    "# Evaluate Model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ac1e8-9bf6-4cf5-bd0a-82cc6c018766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for CNN\n",
    "X_train_cnn = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
    "\n",
    "# CNN Model\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate Model\n",
    "loss, accuracy = model.evaluate(X_test_cnn, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85048b-169b-43d0-8184-ce2bc68195c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
